{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6692a5d4",
   "metadata": {},
   "source": [
    "## Install Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df25cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: seqeval in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from seqeval) (1.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d020a7",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07c32a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\10 Acadamy PRojects\\New folder (4)\\amharic-ecommerce-scraper\\fresh_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from seqeval.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60397bd0",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f135eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conll_dataset(file_path):\n",
    "    sentences, labels = [], []\n",
    "    sentence, label = [], []\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            if line.strip():  # If the line is not empty\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) == 2:  # Ensure the line has exactly two components\n",
    "                    token, tag = parts\n",
    "                    sentence.append(token)\n",
    "                    label.append(tag)\n",
    "                else:\n",
    "                    print(f\"Skipping malformed line: {line.strip()}\")\n",
    "            else:\n",
    "                if sentence:  # Append only if the sentence is not empty\n",
    "                    sentences.append(sentence)\n",
    "                    labels.append(label)\n",
    "                sentence, label = [], []\n",
    "    \n",
    "    if sentence:  # Append any remaining sentence\n",
    "        sentences.append(sentence)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return pd.DataFrame({\"tokens\": sentences, \"ner_tags\": labels})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a03e2",
   "metadata": {},
   "source": [
    "### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2468d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 36\n",
      "Validation set size: 10\n"
     ]
    }
   ],
   "source": [
    "# Function to split the CoNLL dataset into training and validation sets\n",
    "def split_conll_dataset(conll_df, train_ratio=0.8):\n",
    "    # Split the dataset into train and validation sets\n",
    "    train_df, val_df = train_test_split(conll_df, train_size=train_ratio, random_state=42, shuffle=True)\n",
    "\n",
    "    return train_df, val_df\n",
    "\n",
    "# Example usage\n",
    "file_path = \"C:/Users/HP/10 Acadamy PRojects/New folder (4)/amharic-ecommerce-scraper/data/labeled_data_CoNLL.txt\"\n",
    "conll_df = load_conll_dataset(file_path)  # Load the dataset\n",
    "train_dataset, val_dataset = split_conll_dataset(conll_df)  # Split the dataset\n",
    "\n",
    "# Check the sizes of the resulting datasets\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295a2abe",
   "metadata": {},
   "source": [
    "### Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "525eb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label mapping\n",
    "label_to_id = {\n",
    "    \"O\": 0,  # Outside of entity\n",
    "    \"B-Product\": 1,  # Beginning of a Product entity\n",
    "    \"I-Product\": 2,  # Inside of a Product entity\n",
    "    \"B-PRICE\": 3,  # Beginning of a Price entity\n",
    "    \"I-PRICE\": 4,  # Inside of a Price entity\n",
    "    \"B-LOC\": 5,  # Beginning of a Location entity\n",
    "    \"I-LOC\": 6   # Inside of a Location entity\n",
    "}\n",
    "\n",
    "# Reverse mapping for predictions\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189181ed",
   "metadata": {},
   "source": [
    "### Tokenize and Align Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66011af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, tokenizer, label_all_tokens=True):\n",
    "    tokenized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True)\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        # Replace any '0' (zero) with 'O' (uppercase letter O) and 'o' (lowercase) with 'O'\n",
    "        label = ['O' if l in ['0', 'o'] else l for l in label]\n",
    "        \n",
    "        # Convert string labels to integers using label_to_id mapping\n",
    "        label = [label_to_id[l] for l in label]  # Mapping the string NER tags to integers\n",
    "        \n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)  # Padding token\n",
    "            elif word_idx != previous_word_idx:  # First token of a word\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:  # Non-first token of a word\n",
    "                label_ids.append(-100 if not label_all_tokens else label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60280208",
   "metadata": {},
   "source": [
    "### Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84597104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fine-tune the model\n",
    "def train_and_evaluate_model(model_name, train_dataset, val_dataset, label_list, batch_size=16, epochs=15):\n",
    "    print(f\"Training model: {model_name}\")\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))\n",
    "\n",
    "    # Tokenize dataset\n",
    "    # Passing tokenizer inside lambda function\n",
    "    training_dataset = train_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer), batched=True)\n",
    "    evaluation_dataset = val_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer), batched=True)\n",
    "\n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results_{model_name}\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f\"./logs_{model_name}\",\n",
    "        logging_steps=50\n",
    "    )\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=training_dataset,\n",
    "        eval_dataset=evaluation_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation results for {model_name}:\", eval_results)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71deca12",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a26e20ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    # Retrieve predictions and true labels\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    # Convert numeric labels back to their string names using id_to_label mapping\n",
    "    true_labels = [[id_to_label[l] for l in label_row if l != -100] for label_row in labels]\n",
    "    true_preds = [[id_to_label[p] for (p, l) in zip(pred_row, label_row) if l != -100] for pred_row, label_row in zip(preds, labels)]\n",
    "    \n",
    "    # Use seqeval to evaluate the performance\n",
    "    report = classification_report(true_labels, true_preds)\n",
    "    accuracy = accuracy_score(true_labels, true_preds)\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"report\": report}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14936dda",
   "metadata": {},
   "source": [
    "### Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b7adc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compare models\n",
    "def compare_models(models, dataset, label_list):\n",
    "    results = {}\n",
    "    for model_name in models:\n",
    "        eval_result = train_and_evaluate_model(model_name, dataset, label_list)\n",
    "        results[model_name] = eval_result\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1c3d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labeled CoNLL dataset\n",
    "#conll_df = load_conll_dataset(\"/kaggle/input/collection-ner/NER_Collection_data.txt\")\n",
    "#dataset = Dataset.from_pandas(conll_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5752257",
   "metadata": {},
   "source": [
    "### Count Labels in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e24ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count each label in the dataset\n",
    "def count_labels(dataset):\n",
    "    all_labels = [label for labels in dataset['ner_tags'] for label in labels]\n",
    "    label_counts = Counter(all_labels)\n",
    "    \n",
    "    # Print the counts for each label\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"Label: {label}, Count: {count}\")\n",
    "    \n",
    "    return label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3e6fe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: O, Count: 237\n",
      "Label: B-Product, Count: 11\n",
      "Label: I-Product, Count: 281\n",
      "Label: B-LOC, Count: 27\n",
      "Label: I-LOC, Count: 257\n",
      "Label: B-PRICE, Count: 19\n",
      "Label: I-PRICE, Count: 36\n"
     ]
    }
   ],
   "source": [
    "train_label_counts = count_labels(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "158a09d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: B-Product, Count: 6\n",
      "Label: I-Product, Count: 123\n",
      "Label: O, Count: 97\n",
      "Label: B-PRICE, Count: 8\n",
      "Label: I-PRICE, Count: 18\n",
      "Label: B-LOC, Count: 11\n",
      "Label: I-LOC, Count: 80\n"
     ]
    }
   ],
   "source": [
    "evaluation_label_counts = count_labels(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e8f3c4",
   "metadata": {},
   "source": [
    "#### Map labels to correct labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8274c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map incorrect labels to correct labels\n",
    "def map_labels(dataset):\n",
    "    # Define the mapping from incorrect to correct labels\n",
    "    label_mapping = {\n",
    "        'B-PROD': 'B-Product',   # Map 'B-PROD' to 'B-Product'\n",
    "        'B-PRODUCT': 'B-Product', # Map 'B-PRODUCT' to 'B-Product'\n",
    "        'I-PRODUCT': 'I-Product', # Map 'I-PRODUCT' to 'I-Product'\n",
    "        'B-Price': 'B-PRICE',    # Map 'B-Price' to 'B-PRICE'\n",
    "        'I-Price': 'I-PRICE',    # Map 'I-Price' to 'I-PRICE'\n",
    "        'IO': 'O'                # Map 'IO' to 'O'\n",
    "    }\n",
    "    \n",
    "    # Replace the incorrect labels with the correct ones\n",
    "    dataset['ner_tags'] = dataset['ner_tags'].apply(\n",
    "        lambda tags: [label_mapping.get(tag, tag) for tag in tags]\n",
    "    )\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56f4b2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: O, Count: 237\n",
      "Label: B-Product, Count: 11\n",
      "Label: I-Product, Count: 281\n",
      "Label: B-LOC, Count: 27\n",
      "Label: I-LOC, Count: 257\n",
      "Label: B-PRICE, Count: 19\n",
      "Label: I-PRICE, Count: 36\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "train_df = map_labels(train_dataset)\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "\n",
    "# Verify the label counts after remapping\n",
    "label_counts = count_labels(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdab760b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: B-Product, Count: 6\n",
      "Label: I-Product, Count: 123\n",
      "Label: O, Count: 97\n",
      "Label: B-PRICE, Count: 8\n",
      "Label: I-PRICE, Count: 18\n",
      "Label: B-LOC, Count: 11\n",
      "Label: I-LOC, Count: 80\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "val_df = map_labels(val_dataset)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "# Verify the label counts after remapping\n",
    "label_counts = count_labels(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31765797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Function to save the dataset to storage\\ndef save_dataset(dataset, file_path):\\n\\n    Save the modified dataset to a specified file path in CSV format.\\n\\n    Args:\\n        dataset (pd.DataFrame): The DataFrame containing the dataset.\\n        file_path (str): The file path where the dataset will be saved.\\n\\n    dataset.to_csv(file_path, index=False)\\n    print(f\"Dataset saved to {file_path}\")\\n\\n# Save the mapped dataset to a CSV file\\nsave_dataset(conll_df, \"preprocessed_conll_data.txt\")\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Function to save the dataset to storage\n",
    "def save_dataset(dataset, file_path):\n",
    "    \n",
    "    Save the modified dataset to a specified file path in CSV format.\n",
    "    \n",
    "    Args:\n",
    "        dataset (pd.DataFrame): The DataFrame containing the dataset.\n",
    "        file_path (str): The file path where the dataset will be saved.\n",
    "    \n",
    "    dataset.to_csv(file_path, index=False)\n",
    "    print(f\"Dataset saved to {file_path}\")\n",
    "\n",
    "# Save the mapped dataset to a CSV file\n",
    "save_dataset(conll_df, \"preprocessed_conll_data.txt\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb13e7ca",
   "metadata": {},
   "source": [
    "### List Models and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8484d437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# List of entity labels \\nlabel_list = [\\'O\\', \\'B-Product\\', \\'I-Product\\', \\'B-PRICE\\', \\'I-PRICE\\', \\'B-LOC\\', \\'I-LOC\\']\\n\\n# Define models for comparison\\nmodels = [\\n    \"xlm-roberta-base\",  \\n    \"bert-base-multilingual-cased\",  \\n    \"distilbert-base-multilingual-cased\"  \\n]\\n\\n# Compare models\\nresults = compare_models(models, dataset, label_list)\\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# List of entity labels \n",
    "label_list = ['O', 'B-Product', 'I-Product', 'B-PRICE', 'I-PRICE', 'B-LOC', 'I-LOC']\n",
    "\n",
    "# Define models for comparison\n",
    "models = [\n",
    "    \"xlm-roberta-base\",  \n",
    "    \"bert-base-multilingual-cased\",  \n",
    "    \"distilbert-base-multilingual-cased\"  \n",
    "]\n",
    "\n",
    "# Compare models\n",
    "results = compare_models(models, dataset, label_list)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1126bee5",
   "metadata": {},
   "source": [
    "### Print Comparison Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc00a1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Print out comparison results\\nfor model_name, result in results.items():\\n    print(f\"Model: {model_name}\")\\n    print(f\"Accuracy: {result[\\'eval_accuracy\\']}\")\\n    print(result[\\'eval_report\\'])\\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Print out comparison results\n",
    "for model_name, result in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {result['eval_accuracy']}\")\n",
    "    print(result['eval_report'])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07a11464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#API = c912e406b425b51cb31ae3db26397612b381918d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74633b3e",
   "metadata": {},
   "source": [
    "### Fine-tune a Single Model at a Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd923270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate one model\n",
    "def run_single_model(model_name, train_dataset, val_dataset, label_list):\n",
    "    # Train and evaluate the model\n",
    "    eval_result = train_and_evaluate_model(model_name, train_dataset, val_dataset, label_list)\n",
    "    \n",
    "    # Print the evaluation result for the model\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {eval_result['eval_accuracy']}\")\n",
    "    print(eval_result['eval_report'])\n",
    "    \n",
    "    return eval_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a339b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model_name, train_dataset, val_dataset, label_list, batch_size=16, epochs=15):\n",
    "    print(f\"Training model: {model_name}\")\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))\n",
    "\n",
    "    # Tokenize dataset\n",
    "    training_dataset = train_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer), batched=True)\n",
    "    evaluation_dataset = val_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer), batched=True)\n",
    "\n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results_{model_name.replace('/', '-')}\",\n",
    "        eval_strategy=\"epoch\",  # Changed from evaluation_strategy to eval_strategy\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f\"./logs_{model_name.replace('/', '-')}\",\n",
    "        logging_steps=50\n",
    "    )\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=training_dataset,\n",
    "        eval_dataset=evaluation_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation results for {model_name}:\", eval_results)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cceb494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: xlm-roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 36/36 [00:00<00:00, 1626.36 examples/s]\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 746.70 examples/s]\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_27516\\1938220183.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "c:\\Users\\HP\\10 Acadamy PRojects\\New folder (4)\\amharic-ecommerce-scraper\\fresh_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 21:08, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.849491</td>\n",
       "      <td>0.231207</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.10      0.03      0.05        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.00      0.00      0.00        15\n",
       "\n",
       "   micro avg       0.10      0.02      0.03        64\n",
       "   macro avg       0.03      0.01      0.02        64\n",
       "weighted avg       0.05      0.02      0.02        64\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.638613</td>\n",
       "      <td>0.231207</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.10      0.03      0.05        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.00      0.00      0.00        15\n",
       "\n",
       "   micro avg       0.10      0.02      0.03        64\n",
       "   macro avg       0.03      0.01      0.02        64\n",
       "weighted avg       0.05      0.02      0.02        64\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.326082</td>\n",
       "      <td>0.424829</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.01      0.03      0.02        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.02      0.07      0.03        15\n",
       "\n",
       "   micro avg       0.01      0.03      0.02        64\n",
       "   macro avg       0.01      0.03      0.01        64\n",
       "weighted avg       0.01      0.03      0.01        64\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.972253</td>\n",
       "      <td>0.832574</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.09      0.03      0.05        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.00      0.00      0.00        15\n",
       "\n",
       "   micro avg       0.04      0.02      0.02        64\n",
       "   macro avg       0.03      0.01      0.02        64\n",
       "weighted avg       0.05      0.02      0.02        64\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.813783</td>\n",
       "      <td>0.822323</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.11      0.03      0.05        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.00      0.00      0.00        15\n",
       "\n",
       "   micro avg       0.07      0.02      0.03        64\n",
       "   macro avg       0.04      0.01      0.02        64\n",
       "weighted avg       0.06      0.02      0.02        64\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.830296</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.09      0.03      0.05        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.00      0.00      0.00        15\n",
       "\n",
       "   micro avg       0.06      0.02      0.03        64\n",
       "   macro avg       0.03      0.01      0.02        64\n",
       "weighted avg       0.05      0.02      0.02        64\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.594176</td>\n",
       "      <td>0.851936</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.09      0.03      0.05        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.00      0.00      0.00        15\n",
       "\n",
       "   micro avg       0.06      0.02      0.02        64\n",
       "   macro avg       0.03      0.01      0.02        64\n",
       "weighted avg       0.05      0.02      0.02        64\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.534531</td>\n",
       "      <td>0.851936</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.00      0.00      0.00        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.14      0.07      0.09        15\n",
       "\n",
       "   micro avg       0.06      0.02      0.02        64\n",
       "   macro avg       0.05      0.02      0.03        64\n",
       "weighted avg       0.03      0.02      0.02        64\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.475170</td>\n",
       "      <td>0.870159</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.12      0.03      0.05        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.00      0.00      0.00        15\n",
       "\n",
       "   micro avg       0.07      0.02      0.03        64\n",
       "   macro avg       0.04      0.01      0.02        64\n",
       "weighted avg       0.06      0.02      0.03        64\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.459913</td>\n",
       "      <td>0.864465</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.00      0.00      0.00        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.00      0.00      0.00        15\n",
       "\n",
       "   micro avg       0.00      0.00      0.00        64\n",
       "   macro avg       0.00      0.00      0.00        64\n",
       "weighted avg       0.00      0.00      0.00        64\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.461317</td>\n",
       "      <td>0.858770</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.12      0.03      0.05        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.00      0.00      0.00        15\n",
       "\n",
       "   micro avg       0.07      0.02      0.03        64\n",
       "   macro avg       0.04      0.01      0.02        64\n",
       "weighted avg       0.06      0.02      0.03        64\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.436052</td>\n",
       "      <td>0.859909</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.00      0.00      0.00        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.00      0.00      0.00        15\n",
       "\n",
       "   micro avg       0.00      0.00      0.00        64\n",
       "   macro avg       0.00      0.00      0.00        64\n",
       "weighted avg       0.00      0.00      0.00        64\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.415308</td>\n",
       "      <td>0.866743</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.00      0.00      0.00        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.00      0.00      0.00        15\n",
       "\n",
       "   micro avg       0.00      0.00      0.00        64\n",
       "   macro avg       0.00      0.00      0.00        64\n",
       "weighted avg       0.00      0.00      0.00        64\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.414651</td>\n",
       "      <td>0.864465</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.00      0.00      0.00        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.00      0.00      0.00        15\n",
       "\n",
       "   micro avg       0.00      0.00      0.00        64\n",
       "   macro avg       0.00      0.00      0.00        64\n",
       "weighted avg       0.00      0.00      0.00        64\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.413585</td>\n",
       "      <td>0.864465</td>\n",
       "      <td>              precision    recall  f1-score   support\n",
       "\n",
       "         LOC       0.00      0.00      0.00        32\n",
       "       PRICE       0.00      0.00      0.00        17\n",
       "     Product       0.00      0.00      0.00        15\n",
       "\n",
       "   micro avg       0.00      0.00      0.00        64\n",
       "   macro avg       0.00      0.00      0.00        64\n",
       "weighted avg       0.00      0.00      0.00        64\n",
       "</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\10 Acadamy PRojects\\New folder (4)\\amharic-ecommerce-scraper\\fresh_env\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\HP\\10 Acadamy PRojects\\New folder (4)\\amharic-ecommerce-scraper\\fresh_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\HP\\10 Acadamy PRojects\\New folder (4)\\amharic-ecommerce-scraper\\fresh_env\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for xlm-roberta-base: {'eval_loss': 0.41358453035354614, 'eval_accuracy': 0.8644646924829157, 'eval_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.00      0.00      0.00        32\\n       PRICE       0.00      0.00      0.00        17\\n     Product       0.00      0.00      0.00        15\\n\\n   micro avg       0.00      0.00      0.00        64\\n   macro avg       0.00      0.00      0.00        64\\nweighted avg       0.00      0.00      0.00        64\\n', 'eval_runtime': 6.5292, 'eval_samples_per_second': 1.532, 'eval_steps_per_second': 0.153, 'epoch': 15.0}\n",
      "Model: xlm-roberta-base\n",
      "Accuracy: 0.8644646924829157\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.00      0.00      0.00        32\n",
      "       PRICE       0.00      0.00      0.00        17\n",
      "     Product       0.00      0.00      0.00        15\n",
      "\n",
      "   micro avg       0.00      0.00      0.00        64\n",
      "   macro avg       0.00      0.00      0.00        64\n",
      "weighted avg       0.00      0.00      0.00        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of entity labels \n",
    "label_list = ['O', 'B-Product', 'I-Product', 'B-PRICE', 'I-PRICE', 'B-LOC', 'I-LOC']\n",
    "\n",
    "# Define the model to run\n",
    "model_name = \"xlm-roberta-base\"\n",
    "\n",
    "# Run and evaluate the model\n",
    "eval_result = run_single_model(model_name, train_dataset, val_dataset, label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afde48a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fresh_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

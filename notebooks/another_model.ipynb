{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "722cbc22",
   "metadata": {},
   "source": [
    "## Install Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19fb8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: seqeval in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from seqeval) (1.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\10 acadamy projects\\new folder (4)\\amharic-ecommerce-scraper\\fresh_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcce583",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22565a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from seqeval.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb3e52",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43d05fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conll_dataset(file_path):\n",
    "    sentences, labels = [], []\n",
    "    sentence, label = [], []\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            if line.strip():  # If the line is not empty\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) == 2:  # Ensure the line has exactly two components\n",
    "                    token, tag = parts\n",
    "                    sentence.append(token)\n",
    "                    label.append(tag)\n",
    "                else:\n",
    "                    print(f\"Skipping malformed line: {line.strip()}\")\n",
    "            else:\n",
    "                if sentence:  # Append only if the sentence is not empty\n",
    "                    sentences.append(sentence)\n",
    "                    labels.append(label)\n",
    "                sentence, label = [], []\n",
    "    \n",
    "    if sentence:  # Append any remaining sentence\n",
    "        sentences.append(sentence)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return pd.DataFrame({\"tokens\": sentences, \"ner_tags\": labels})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be68aae9",
   "metadata": {},
   "source": [
    "### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52e43f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 36\n",
      "Validation set size: 10\n"
     ]
    }
   ],
   "source": [
    "# Function to split the CoNLL dataset into training and validation sets\n",
    "def split_conll_dataset(conll_df, train_ratio=0.8):\n",
    "    # Split the dataset into train and validation sets\n",
    "    train_df, val_df = train_test_split(conll_df, train_size=train_ratio, random_state=42, shuffle=True)\n",
    "\n",
    "    return train_df, val_df\n",
    "\n",
    "# Example usage\n",
    "file_path = \"C:/Users/HP/10 Acadamy PRojects/New folder (4)/amharic-ecommerce-scraper/data/labeled_data_CoNLL.txt\"\n",
    "conll_df = load_conll_dataset(file_path)  # Load the dataset\n",
    "train_dataset, val_dataset = split_conll_dataset(conll_df)  # Split the dataset\n",
    "\n",
    "# Check the sizes of the resulting datasets\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91127f4",
   "metadata": {},
   "source": [
    "### Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "668f3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label mapping\n",
    "label_to_id = {\n",
    "    \"O\": 0,  # Outside of entity\n",
    "    \"B-Product\": 1,  # Beginning of a Product entity\n",
    "    \"I-Product\": 2,  # Inside of a Product entity\n",
    "    \"B-PRICE\": 3,  # Beginning of a Price entity\n",
    "    \"I-PRICE\": 4,  # Inside of a Price entity\n",
    "    \"B-LOC\": 5,  # Beginning of a Location entity\n",
    "    \"I-LOC\": 6   # Inside of a Location entity\n",
    "}\n",
    "\n",
    "# Reverse mapping for predictions\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f3597",
   "metadata": {},
   "source": [
    "### Tokenize and Align Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69a27e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, tokenizer, label_all_tokens=True):\n",
    "    tokenized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True)\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        # Replace any '0' (zero) with 'O' (uppercase letter O) and 'o' (lowercase) with 'O'\n",
    "        label = ['O' if l in ['0', 'o'] else l for l in label]\n",
    "        \n",
    "        # Convert string labels to integers using label_to_id mapping\n",
    "        label = [label_to_id[l] for l in label]  # Mapping the string NER tags to integers\n",
    "        \n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)  # Padding token\n",
    "            elif word_idx != previous_word_idx:  # First token of a word\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:  # Non-first token of a word\n",
    "                label_ids.append(-100 if not label_all_tokens else label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34657d62",
   "metadata": {},
   "source": [
    "### Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d8853be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fine-tune the model\n",
    "def train_and_evaluate_model(model_name, train_dataset, val_dataset, label_list, batch_size=16, epochs=15):\n",
    "    print(f\"Training model: {model_name}\")\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))\n",
    "\n",
    "    # Tokenize dataset\n",
    "    # Passing tokenizer inside lambda function\n",
    "    training_dataset = train_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer), batched=True)\n",
    "    evaluation_dataset = val_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer), batched=True)\n",
    "\n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results_{model_name}\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f\"./logs_{model_name}\",\n",
    "        logging_steps=50\n",
    "    )\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=training_dataset,\n",
    "        eval_dataset=evaluation_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation results for {model_name}:\", eval_results)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3054f1",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ef43885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    # Retrieve predictions and true labels\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    # Convert numeric labels back to their string names using id_to_label mapping\n",
    "    true_labels = [[id_to_label[l] for l in label_row if l != -100] for label_row in labels]\n",
    "    true_preds = [[id_to_label[p] for (p, l) in zip(pred_row, label_row) if l != -100] for pred_row, label_row in zip(preds, labels)]\n",
    "    \n",
    "    # Use seqeval to evaluate the performance\n",
    "    report = classification_report(true_labels, true_preds)\n",
    "    accuracy = accuracy_score(true_labels, true_preds)\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"report\": report}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9be881",
   "metadata": {},
   "source": [
    "### Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c78aef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compare models\n",
    "def compare_models(models, dataset, label_list):\n",
    "    results = {}\n",
    "    for model_name in models:\n",
    "        eval_result = train_and_evaluate_model(model_name, dataset, label_list)\n",
    "        results[model_name] = eval_result\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87124046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labeled CoNLL dataset\n",
    "#conll_df = load_conll_dataset(\"/kaggle/input/collection-ner/NER_Collection_data.txt\")\n",
    "#dataset = Dataset.from_pandas(conll_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e7938",
   "metadata": {},
   "source": [
    "### Count Labels in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e90ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count each label in the dataset\n",
    "def count_labels(dataset):\n",
    "    all_labels = [label for labels in dataset['ner_tags'] for label in labels]\n",
    "    label_counts = Counter(all_labels)\n",
    "    \n",
    "    # Print the counts for each label\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"Label: {label}, Count: {count}\")\n",
    "    \n",
    "    return label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c482840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: O, Count: 237\n",
      "Label: B-Product, Count: 11\n",
      "Label: I-Product, Count: 281\n",
      "Label: B-LOC, Count: 27\n",
      "Label: I-LOC, Count: 257\n",
      "Label: B-PRICE, Count: 19\n",
      "Label: I-PRICE, Count: 36\n"
     ]
    }
   ],
   "source": [
    "train_label_counts = count_labels(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90294ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: B-Product, Count: 6\n",
      "Label: I-Product, Count: 123\n",
      "Label: O, Count: 97\n",
      "Label: B-PRICE, Count: 8\n",
      "Label: I-PRICE, Count: 18\n",
      "Label: B-LOC, Count: 11\n",
      "Label: I-LOC, Count: 80\n"
     ]
    }
   ],
   "source": [
    "evaluation_label_counts = count_labels(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9f76d7",
   "metadata": {},
   "source": [
    "#### Map labels to correct labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e76cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map incorrect labels to correct labels\n",
    "def map_labels(dataset):\n",
    "    # Define the mapping from incorrect to correct labels\n",
    "    label_mapping = {\n",
    "        'B-PROD': 'B-Product',   # Map 'B-PROD' to 'B-Product'\n",
    "        'B-PRODUCT': 'B-Product', # Map 'B-PRODUCT' to 'B-Product'\n",
    "        'I-PRODUCT': 'I-Product', # Map 'I-PRODUCT' to 'I-Product'\n",
    "        'B-Price': 'B-PRICE',    # Map 'B-Price' to 'B-PRICE'\n",
    "        'I-Price': 'I-PRICE',    # Map 'I-Price' to 'I-PRICE'\n",
    "        'IO': 'O'                # Map 'IO' to 'O'\n",
    "    }\n",
    "    \n",
    "    # Replace the incorrect labels with the correct ones\n",
    "    dataset['ner_tags'] = dataset['ner_tags'].apply(\n",
    "        lambda tags: [label_mapping.get(tag, tag) for tag in tags]\n",
    "    )\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81cd0867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: O, Count: 237\n",
      "Label: B-Product, Count: 11\n",
      "Label: I-Product, Count: 281\n",
      "Label: B-LOC, Count: 27\n",
      "Label: I-LOC, Count: 257\n",
      "Label: B-PRICE, Count: 19\n",
      "Label: I-PRICE, Count: 36\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "train_df = map_labels(train_dataset)\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "\n",
    "# Verify the label counts after remapping\n",
    "label_counts = count_labels(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94e639df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: B-Product, Count: 6\n",
      "Label: I-Product, Count: 123\n",
      "Label: O, Count: 97\n",
      "Label: B-PRICE, Count: 8\n",
      "Label: I-PRICE, Count: 18\n",
      "Label: B-LOC, Count: 11\n",
      "Label: I-LOC, Count: 80\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "val_df = map_labels(val_dataset)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "# Verify the label counts after remapping\n",
    "label_counts = count_labels(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "017937f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Function to save the dataset to storage\\ndef save_dataset(dataset, file_path):\\n\\n    Save the modified dataset to a specified file path in CSV format.\\n\\n    Args:\\n        dataset (pd.DataFrame): The DataFrame containing the dataset.\\n        file_path (str): The file path where the dataset will be saved.\\n\\n    dataset.to_csv(file_path, index=False)\\n    print(f\"Dataset saved to {file_path}\")\\n\\n# Save the mapped dataset to a CSV file\\nsave_dataset(conll_df, \"preprocessed_conll_data.txt\")\\n\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Function to save the dataset to storage\n",
    "def save_dataset(dataset, file_path):\n",
    "    \n",
    "    Save the modified dataset to a specified file path in CSV format.\n",
    "    \n",
    "    Args:\n",
    "        dataset (pd.DataFrame): The DataFrame containing the dataset.\n",
    "        file_path (str): The file path where the dataset will be saved.\n",
    "    \n",
    "    dataset.to_csv(file_path, index=False)\n",
    "    print(f\"Dataset saved to {file_path}\")\n",
    "\n",
    "# Save the mapped dataset to a CSV file\n",
    "save_dataset(conll_df, \"preprocessed_conll_data.txt\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46da6666",
   "metadata": {},
   "source": [
    "### List Models and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50f686ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# List of entity labels \\nlabel_list = [\\'O\\', \\'B-Product\\', \\'I-Product\\', \\'B-PRICE\\', \\'I-PRICE\\', \\'B-LOC\\', \\'I-LOC\\']\\n\\n# Define models for comparison\\nmodels = [\\n    \"xlm-roberta-base\",  \\n    \"bert-base-multilingual-cased\",  \\n    \"distilbert-base-multilingual-cased\"  \\n]\\n\\n# Compare models\\nresults = compare_models(models, dataset, label_list)\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# List of entity labels \n",
    "label_list = ['O', 'B-Product', 'I-Product', 'B-PRICE', 'I-PRICE', 'B-LOC', 'I-LOC']\n",
    "\n",
    "# Define models for comparison\n",
    "models = [\n",
    "    \"xlm-roberta-base\",  \n",
    "    \"bert-base-multilingual-cased\",  \n",
    "    \"distilbert-base-multilingual-cased\"  \n",
    "]\n",
    "\n",
    "# Compare models\n",
    "results = compare_models(models, dataset, label_list)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b519a1a9",
   "metadata": {},
   "source": [
    "### Print Comparison Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8e9c2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Print out comparison results\\nfor model_name, result in results.items():\\n    print(f\"Model: {model_name}\")\\n    print(f\"Accuracy: {result[\\'eval_accuracy\\']}\")\\n    print(result[\\'eval_report\\'])\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Print out comparison results\n",
    "for model_name, result in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {result['eval_accuracy']}\")\n",
    "    print(result['eval_report'])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "729fa264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#API = c912e406b425b51cb31ae3db26397612b381918d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d739d",
   "metadata": {},
   "source": [
    "### Fine-tune a Single Model at a Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58d0f5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate one model\n",
    "def run_single_model(model_name, train_dataset, val_dataset, label_list):\n",
    "    # Train and evaluate the model\n",
    "    eval_result = train_and_evaluate_model(model_name, train_dataset, val_dataset, label_list)\n",
    "    \n",
    "    # Print the evaluation result for the model\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {eval_result['eval_accuracy']}\")\n",
    "    print(eval_result['eval_report'])\n",
    "    \n",
    "    return eval_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ff28ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model_name, train_dataset, val_dataset, label_list, batch_size=16, epochs=15):\n",
    "    print(f\"Training model: {model_name}\")\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))\n",
    "\n",
    "    # Tokenize dataset\n",
    "    training_dataset = train_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer), batched=True)\n",
    "    evaluation_dataset = val_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer), batched=True)\n",
    "\n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results_{model_name.replace('/', '-')}\",\n",
    "        eval_strategy=\"epoch\",  # Changed from evaluation_strategy to eval_strategy\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f\"./logs_{model_name.replace('/', '-')}\",\n",
    "        logging_steps=50\n",
    "    )\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=training_dataset,\n",
    "        eval_dataset=evaluation_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation results for {model_name}:\", eval_results)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f43f76fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: distilbert-base-multilingual-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/pytorch_model.bin: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "distilbert-base-multilingual-cased does not appear to have a file named pytorch_model.bin but there is a file for TensorFlow weights. Use `from_tf=True` to load this model from those weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mdistilbert-base-multilingual-cased\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Run and evaluate the model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m eval_result = \u001b[43mrun_single_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mrun_single_model\u001b[39m\u001b[34m(model_name, train_dataset, val_dataset, label_list)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single_model\u001b[39m(model_name, train_dataset, val_dataset, label_list):\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Train and evaluate the model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     eval_result = \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Print the evaluation result for the model\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mtrain_and_evaluate_model\u001b[39m\u001b[34m(model_name, train_dataset, val_dataset, label_list, batch_size, epochs)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load tokenizer and model\u001b[39;00m\n\u001b[32m      5\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43mAutoModelForTokenClassification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabel_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Tokenize dataset\u001b[39;00m\n\u001b[32m      9\u001b[39m training_dataset = train_dataset.map(\u001b[38;5;28;01mlambda\u001b[39;00m x: tokenize_and_align_labels(x, tokenizer), batched=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (4)\\amharic-ecommerce-scraper\\fresh_env\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:571\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    575\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (4)\\amharic-ecommerce-scraper\\fresh_env\\Lib\\site-packages\\transformers\\modeling_utils.py:279\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    281\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (4)\\amharic-ecommerce-scraper\\fresh_env\\Lib\\site-packages\\transformers\\modeling_utils.py:4260\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4251\u001b[39m     gguf_file\n\u001b[32m   4252\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4253\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[32m   4254\u001b[39m ):\n\u001b[32m   4255\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   4256\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4260\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4262\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4265\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4267\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4273\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4275\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4276\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4278\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4279\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (4)\\amharic-ecommerce-scraper\\fresh_env\\Lib\\site-packages\\transformers\\modeling_utils.py:1080\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash)\u001b[39m\n\u001b[32m   1072\u001b[39m has_file_kwargs = {\n\u001b[32m   1073\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrevision\u001b[39m\u001b[33m\"\u001b[39m: revision,\n\u001b[32m   1074\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproxies\u001b[39m\u001b[33m\"\u001b[39m: proxies,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1077\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlocal_files_only\u001b[39m\u001b[33m\"\u001b[39m: local_files_only,\n\u001b[32m   1078\u001b[39m }\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_file(pretrained_model_name_or_path, TF2_WEIGHTS_NAME, **has_file_kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1080\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m   1081\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not appear to have a file named\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1082\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but there is a file for TensorFlow weights.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1083\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Use `from_tf=True` to load this model from those weights.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1084\u001b[39m     )\n\u001b[32m   1085\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m has_file(pretrained_model_name_or_path, FLAX_WEIGHTS_NAME, **has_file_kwargs):\n\u001b[32m   1086\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m   1087\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not appear to have a file named\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1088\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but there is a file for Flax weights. Use\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1089\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m `from_flax=True` to load this model from those weights.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1090\u001b[39m     )\n",
      "\u001b[31mOSError\u001b[39m: distilbert-base-multilingual-cased does not appear to have a file named pytorch_model.bin but there is a file for TensorFlow weights. Use `from_tf=True` to load this model from those weights."
     ]
    }
   ],
   "source": [
    "# List of entity labels \n",
    "label_list = ['O', 'B-Product', 'I-Product', 'B-PRICE', 'I-PRICE', 'B-LOC', 'I-LOC']\n",
    "\n",
    "# Define the model to run\n",
    "model_name = \"distilbert-base-multilingual-cased\"\n",
    "\n",
    "# Run and evaluate the model\n",
    "eval_result = run_single_model(model_name, train_dataset, val_dataset, label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcddd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del /s /q C:\\Users\\HP\\.cache\\huggingface\\hub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fresh_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa918da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7edac923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys  \n",
    "import os\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "from telethon.sync import TelegramClient\n",
    "import re\n",
    "import emoji\n",
    "import csv\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3074d4a5",
   "metadata": {},
   "source": [
    "# Selecting 5 channels nand Scrape messages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef200e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping channel: ZemenExpress ...\n",
      "✅ Completed scraping ZemenExpress\n",
      "Scraping channel: meneshayeofficial ...\n",
      "✅ Completed scraping meneshayeofficial\n",
      "Scraping channel: ethio_brand_collection ...\n",
      "✅ Completed scraping ethio_brand_collection\n",
      "Scraping channel: Shewabrand ...\n",
      "✅ Completed scraping Shewabrand\n",
      "Scraping channel: qnashcom ...\n",
      "✅ Completed scraping qnashcom\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Allow nested asyncio loops (needed in notebooks like Jupyter)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('.env')\n",
    "\n",
    "# Retrieve API credentials\n",
    "API_ID = os.getenv('TG_API_ID')\n",
    "API_HASH = os.getenv('TG_API_HASH')\n",
    "\n",
    "if API_ID is None:\n",
    "    raise ValueError(\"API_ID not found in environment variables\")\n",
    "else:\n",
    "    API_ID = int(API_ID)\n",
    "\n",
    "if API_HASH is None:\n",
    "    raise ValueError(\"API_HASH not found in environment variables\")\n",
    "\n",
    "# Async function to fetch messages and media from a channel\n",
    "async def fetch_channel_messages(client, channel_handle, csv_writer, download_folder):\n",
    "    channel_entity = await client.get_entity(channel_handle)\n",
    "    channel_name = channel_entity.title\n",
    "    async for msg in client.iter_messages(channel_entity, limit=10000):\n",
    "        media_file_path = None\n",
    "        if msg.media and hasattr(msg.media, 'photo'):\n",
    "            filename = f\"{channel_handle}_{msg.id}.jpg\"\n",
    "            media_file_path = os.path.join(download_folder, filename)\n",
    "            await client.download_media(msg.media, media_file_path)\n",
    "\n",
    "        csv_writer.writerow([\n",
    "            channel_name,\n",
    "            channel_handle,\n",
    "            msg.id,\n",
    "            msg.message,\n",
    "            msg.date,\n",
    "            media_file_path\n",
    "        ])\n",
    "\n",
    "# Main async function to run the scraper\n",
    "async def run_scraper():\n",
    "    client = TelegramClient('session_scraper', API_ID, API_HASH)\n",
    "    await client.start()\n",
    "\n",
    "    # Define where to save data and images\n",
    "    base_folder = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (4)\\amharic-ecommerce-scraper\\data\"\n",
    "    media_folder = os.path.join(base_folder, 'downloaded_images')\n",
    "    os.makedirs(media_folder, exist_ok=True)\n",
    "\n",
    "    csv_path = os.path.join(base_folder, 'output_telegram_data.csv')\n",
    "\n",
    "    with open(csv_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['Channel Title', 'Channel Handle', 'Message ID', 'Content', 'Timestamp', 'Media File'])\n",
    "\n",
    "  target_channels = [\n",
    "            'ZemenExpress',\n",
    "            'meneshayeofficial',\n",
    "            'ethio_brand_collection',\n",
    "            'Shewabrand',\n",
    "            'qnashcom'\n",
    "        ]\n",
    "\n",
    "        for channel in target_channels:\n",
    "            print(f\"Scraping channel: {channel} ...\")\n",
    "            await fetch_channel_messages(client, channel, writer, media_folder)\n",
    "            print(f\"✅ Completed scraping {channel}\")\n",
    "\n",
    "    await client.disconnect()\n",
    "\n",
    "# Run the scraper in a notebook or async environment\n",
    "await run_scraper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683cb13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a45bdbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86d4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df4848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5294b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
